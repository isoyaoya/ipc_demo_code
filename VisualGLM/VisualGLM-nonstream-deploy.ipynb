{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5660b06-00e1-4436-8293-b3b3381c626e",
   "metadata": {},
   "source": [
    "## 1.使用Sagemaker部署VisualGLM模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1bbbd74b-132c-4c2c-83c0-0f78a0213c74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install huggingface-hub -Uq\n",
    "!pip install -Uq sagemaker "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8afda09-8473-41b3-9f18-559adeec52f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install sagemaker pip --upgrade  --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4147ccf0-4759-43f2-bc64-6a5caf4b45c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import snapshot_download\n",
    "from pathlib import Path\n",
    "\n",
    "local_model_path = Path(\"./LLM_visualglm_stream_model\")\n",
    "local_model_path.mkdir(exist_ok=True)\n",
    "model_name = \"THUDM/visualglm-6b\"\n",
    "commit_hash = \"f4f759acde0926fefcd35e2c626e08adb452eff8\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aaac9225-7cf3-4a10-8543-ad1528b9305c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6777e734fce844ddb86366ad0b9eaea1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 18 files:   0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'LLM_visualglm_stream_model/models--THUDM--visualglm-6b/snapshots/f4f759acde0926fefcd35e2c626e08adb452eff8'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snapshot_download(repo_id=model_name, cache_dir=local_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d9ded3-2ce0-42ab-9bf9-bcf3cffcd5d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "71974a2d-2443-4e2b-b310-8ba754db92fd",
   "metadata": {},
   "source": [
    "### 1.1 把模型拷贝到S3为后续部署做准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "279dad99-a6bc-4b53-9d13-9b49f17103d7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "from sagemaker import image_uris\n",
    "import jinja2\n",
    "import boto3\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "\n",
    "role = sagemaker.get_execution_role()  # execution role for the endpoint\n",
    "sess = sagemaker.session.Session()  # sagemaker session for interacting with different AWS APIs\n",
    "bucket = sess.default_bucket()  # bucket to house artifacts\n",
    "\n",
    "region = sess._region_name\n",
    "account_id = sess.account_id()\n",
    "\n",
    "s3_client = boto3.client(\"s3\")\n",
    "sm_client = boto3.client(\"sagemaker\")\n",
    "smr_client = boto3.client(\"sagemaker-runtime\")\n",
    "\n",
    "jinja_env = jinja2.Environment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e11f7b37-fc8f-44b0-a8ec-a49850ae3a7e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3_code_prefix: LLM_visualglm_deploy_code\n",
      "model_snapshot_path: LLM_visualglm_stream_model/models--THUDM--visualglm-6b/snapshots/f4f759acde0926fefcd35e2c626e08adb452eff8\n"
     ]
    }
   ],
   "source": [
    "s3_model_prefix = \"LLM_visualglm_model\"  # folder where model checkpoint will go\n",
    "model_snapshot_path = list(local_model_path.glob(\"**/snapshots/*\"))[0]\n",
    "s3_code_prefix = \"LLM_visualglm_deploy_code\"\n",
    "\n",
    "print(f\"s3_code_prefix: {s3_code_prefix}\")\n",
    "print(f\"model_snapshot_path: {model_snapshot_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "560c44ed-6ca4-4caa-b596-92f95da01849",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: LLM_visualglm_stream_model/models--THUDM--visualglm-6b/snapshots/f4f759acde0926fefcd35e2c626e08adb452eff8/MODEL_LICENSE to s3://sagemaker-us-west-2-691188012938/LLM_visualglm_model/MODEL_LICENSE\n",
      "upload: LLM_visualglm_stream_model/models--THUDM--visualglm-6b/snapshots/f4f759acde0926fefcd35e2c626e08adb452eff8/config.json to s3://sagemaker-us-west-2-691188012938/LLM_visualglm_model/config.json\n",
      "upload: LLM_visualglm_stream_model/models--THUDM--visualglm-6b/snapshots/f4f759acde0926fefcd35e2c626e08adb452eff8/README.md to s3://sagemaker-us-west-2-691188012938/LLM_visualglm_model/README.md\n",
      "upload: LLM_visualglm_stream_model/models--THUDM--visualglm-6b/snapshots/f4f759acde0926fefcd35e2c626e08adb452eff8/configuration_chatglm.py to s3://sagemaker-us-west-2-691188012938/LLM_visualglm_model/configuration_chatglm.py\n",
      "upload: LLM_visualglm_stream_model/models--THUDM--visualglm-6b/snapshots/f4f759acde0926fefcd35e2c626e08adb452eff8/LICENSE to s3://sagemaker-us-west-2-691188012938/LLM_visualglm_model/LICENSE\n",
      "upload: LLM_visualglm_stream_model/models--THUDM--visualglm-6b/snapshots/f4f759acde0926fefcd35e2c626e08adb452eff8/modeling_chatglm.py to s3://sagemaker-us-west-2-691188012938/LLM_visualglm_model/modeling_chatglm.py\n",
      "upload: LLM_visualglm_stream_model/models--THUDM--visualglm-6b/snapshots/f4f759acde0926fefcd35e2c626e08adb452eff8/.gitattributes to s3://sagemaker-us-west-2-691188012938/LLM_visualglm_model/.gitattributes\n",
      "upload: LLM_visualglm_stream_model/models--THUDM--visualglm-6b/snapshots/f4f759acde0926fefcd35e2c626e08adb452eff8/ice_text.model to s3://sagemaker-us-west-2-691188012938/LLM_visualglm_model/ice_text.model\n",
      "upload: LLM_visualglm_stream_model/models--THUDM--visualglm-6b/snapshots/f4f759acde0926fefcd35e2c626e08adb452eff8/pytorch_model-00005-of-00005.bin to s3://sagemaker-us-west-2-691188012938/LLM_visualglm_model/pytorch_model-00005-of-00005.bin\n",
      "upload: LLM_visualglm_stream_model/models--THUDM--visualglm-6b/snapshots/f4f759acde0926fefcd35e2c626e08adb452eff8/pytorch_model.bin.index.json to s3://sagemaker-us-west-2-691188012938/LLM_visualglm_model/pytorch_model.bin.index.json\n",
      "upload: LLM_visualglm_stream_model/models--THUDM--visualglm-6b/snapshots/f4f759acde0926fefcd35e2c626e08adb452eff8/quantization.py to s3://sagemaker-us-west-2-691188012938/LLM_visualglm_model/quantization.py\n",
      "upload: LLM_visualglm_stream_model/models--THUDM--visualglm-6b/snapshots/f4f759acde0926fefcd35e2c626e08adb452eff8/tokenization_chatglm.py to s3://sagemaker-us-west-2-691188012938/LLM_visualglm_model/tokenization_chatglm.py\n",
      "upload: LLM_visualglm_stream_model/models--THUDM--visualglm-6b/snapshots/f4f759acde0926fefcd35e2c626e08adb452eff8/tokenizer_config.json to s3://sagemaker-us-west-2-691188012938/LLM_visualglm_model/tokenizer_config.json\n",
      "upload: LLM_visualglm_stream_model/models--THUDM--visualglm-6b/snapshots/f4f759acde0926fefcd35e2c626e08adb452eff8/visual.py to s3://sagemaker-us-west-2-691188012938/LLM_visualglm_model/visual.py\n",
      "upload: LLM_visualglm_stream_model/models--THUDM--visualglm-6b/snapshots/f4f759acde0926fefcd35e2c626e08adb452eff8/pytorch_model-00003-of-00005.bin to s3://sagemaker-us-west-2-691188012938/LLM_visualglm_model/pytorch_model-00003-of-00005.bin\n",
      "upload: LLM_visualglm_stream_model/models--THUDM--visualglm-6b/snapshots/f4f759acde0926fefcd35e2c626e08adb452eff8/pytorch_model-00002-of-00005.bin to s3://sagemaker-us-west-2-691188012938/LLM_visualglm_model/pytorch_model-00002-of-00005.bin\n",
      "upload: LLM_visualglm_stream_model/models--THUDM--visualglm-6b/snapshots/f4f759acde0926fefcd35e2c626e08adb452eff8/pytorch_model-00004-of-00005.bin to s3://sagemaker-us-west-2-691188012938/LLM_visualglm_model/pytorch_model-00004-of-00005.bin\n",
      "upload: LLM_visualglm_stream_model/models--THUDM--visualglm-6b/snapshots/f4f759acde0926fefcd35e2c626e08adb452eff8/pytorch_model-00001-of-00005.bin to s3://sagemaker-us-west-2-691188012938/LLM_visualglm_model/pytorch_model-00001-of-00005.bin\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp --recursive {model_snapshot_path} s3://{bucket}/{s3_model_prefix}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6efe27fb-cc07-4a15-9dce-baa520b2af9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf {local_model_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca3d7fc-de97-4d1d-b1f0-d396daa81620",
   "metadata": {},
   "source": [
    "### 1.2 模型部署准备（entrypoint脚本，容器镜像，服务配置)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a198f31e-f164-4a82-a92d-a787037231fa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image going to be used is ---- > 763104351884.dkr.ecr.us-west-2.amazonaws.com/djl-inference:0.22.1-deepspeed0.9.2-cu118\n"
     ]
    }
   ],
   "source": [
    "inference_image_uri = image_uris.retrieve(\n",
    "    framework=\"djl-deepspeed\",\n",
    "    region=sess.boto_session.region_name,\n",
    "    version=\"0.22.1\"\n",
    ")\n",
    "print(f\"Image going to be used is ---- > {inference_image_uri}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc3ef47c-eaf8-46f9-ac07-464a680ca84c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mkdir -p LLM_visualglm_deploy_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "30de600a-4877-4a32-a866-7b112d2ac99b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting LLM_visualglm_deploy_code/model.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile LLM_visualglm_deploy_code/model.py\n",
    "from djl_python import Input, Output\n",
    "import requests\n",
    "import torch\n",
    "import logging\n",
    "import math\n",
    "import os\n",
    "from PIL import Image\n",
    "import base64\n",
    "from io import BytesIO\n",
    "import json\n",
    "\n",
    "\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "model = None\n",
    "tokenizer = None\n",
    "\n",
    "DEVICE = \"cuda\"\n",
    "DEVICE_ID = \"0\"\n",
    "CUDA_DEVICE = f\"{DEVICE}:{DEVICE_ID}\" if DEVICE_ID else DEVICE\n",
    "def torch_gc():\n",
    "    if torch.cuda.is_available():\n",
    "        with torch.cuda.device(CUDA_DEVICE):\n",
    "            torch.cuda.empty_cache()\n",
    "            torch.cuda.ipc_collect()\n",
    "            \n",
    "            \n",
    "def parse_text(text):\n",
    "    \"\"\"copy from https://github.com/GaiZhenbiao/ChuanhuChatGPT/\"\"\"\n",
    "    lines = text.split(\"\\n\")\n",
    "    lines = [line for line in lines if line != \"\"]\n",
    "    count = 0\n",
    "    for i, line in enumerate(lines):\n",
    "        if \"```\" in line:\n",
    "            count += 1\n",
    "            items = line.split('`')\n",
    "            if count % 2 == 1:\n",
    "                lines[i] = f'<pre><code class=\"language-{items[-1]}\">'\n",
    "            else:\n",
    "                lines[i] = f'<br></code></pre>'\n",
    "        else:\n",
    "            if i > 0:\n",
    "                if count % 2 == 1:\n",
    "                    line = line.replace(\"`\", \"\\`\")\n",
    "                    line = line.replace(\"<\", \"&lt;\")\n",
    "                    line = line.replace(\">\", \"&gt;\")\n",
    "                    line = line.replace(\" \", \"&nbsp;\")\n",
    "                    line = line.replace(\"*\", \"&ast;\")\n",
    "                    line = line.replace(\"_\", \"&lowbar;\")\n",
    "                    line = line.replace(\"-\", \"&#45;\")\n",
    "                    line = line.replace(\".\", \"&#46;\")\n",
    "                    line = line.replace(\"!\", \"&#33;\")\n",
    "                    line = line.replace(\"(\", \"&#40;\")\n",
    "                    line = line.replace(\")\", \"&#41;\")\n",
    "                    line = line.replace(\"$\", \"&#36;\")\n",
    "                lines[i] = \"<br>\"+line\n",
    "    text = \"\".join(lines)\n",
    "    return text\n",
    "\n",
    "def load_model(properties):\n",
    "    global tokenizer,model\n",
    "    tensor_parallel = properties[\"tensor_parallel_degree\"]\n",
    "    model_location = properties['model_dir']\n",
    "    if \"model_id\" in properties:\n",
    "        model_location = properties['model_id']\n",
    "    logging.info(f\"Loading model in {model_location}\")\n",
    "    \n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_location, trust_remote_code=True)\n",
    "   \n",
    "    model = AutoModel.from_pretrained(model_location, trust_remote_code=True).quantize(8).half().cuda()\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    return model, tokenizer\n",
    "            \n",
    "\n",
    "\n",
    "def handle(inputs: Input):\n",
    "    global model, tokenizer\n",
    "    if not model:\n",
    "        model, tokenizer = load_model(inputs.get_properties())\n",
    "    \n",
    "    if inputs.is_empty():\n",
    "        return None\n",
    "    data = inputs.get_as_json()\n",
    "    \n",
    "    input_sentences = data[\"inputs\"]\n",
    "    image_path=data[\"image\"]\n",
    "    if image_path is None:\n",
    "        return  Output().add_as_json({ \"outputs\":\"图片不能为空。请重新上传图片并重试。\"})\n",
    "    ##测试链接是否能下载\n",
    "    if image_path.startswith(\"http\"):\n",
    "        try:\n",
    "            requests.get(image_path, timeout=10)\n",
    "        except:\n",
    "            return  Output().add_as_json({ \"outputs\":f'cannot download file from image_path:{image_path}'})\n",
    "\n",
    "    \n",
    "    #try:\n",
    "    #    requests.get(image_path, timeout=10)\n",
    "    #except:\n",
    "    #    return  Output().add_as_json({ \"outputs\":f'cannot download file from image_path:{image_path}'})\n",
    "\n",
    "    params = data[\"parameters\"]\n",
    "    history = data[\"history\"]\n",
    "    print(f'input prompt:{input_sentences}')\n",
    "    \n",
    "    response, history = model.chat(tokenizer,image_path, input_sentences, history=history)\n",
    "    result = {\"outputs\": parse_text(response)}\n",
    "    return Output().add_as_json(result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b8bf8e5d-35b7-4071-b082-69d9ecf25416",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-west-2-691188012938/LLM_visualglm_model/\n"
     ]
    }
   ],
   "source": [
    "s3url=f's3://{bucket}/{s3_model_prefix}/'\n",
    "print(s3url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a92c7a0c-6ba9-4cbe-ae4e-dfc5ed5a4368",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing LLM_visualglm_deploy_code/serving.properties\n"
     ]
    }
   ],
   "source": [
    "%%writefile LLM_visualglm_deploy_code/serving.properties\n",
    "engine=Python\n",
    "option.tensor_parallel_degree=1\n",
    "option.s3url= {{s3url}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "307c931c-22cf-4795-bbeb-3c4e8b521c51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting LLM_visualglm_deploy_code/requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile LLM_visualglm_deploy_code/requirements.txt\n",
    "transformers==4.30.2\n",
    "SwissArmyTransformer==0.3.6\n",
    "accelerate==0.20.3\n",
    "cpm_kernels==1.0.11\n",
    "torchvision==0.15.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f4de8925-c94d-4a0f-9efa-fda920ab89d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1\t\u001b[36mengine\u001b[39;49;00m=\u001b[33mPython\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "     2\t\u001b[36moption.tensor_parallel_degree\u001b[39;49;00m=\u001b[33m1\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "     3\t\u001b[36moption.s3url\u001b[39;49;00m=\u001b[37m \u001b[39;49;00m\u001b[33ms3://sagemaker-us-west-2-691188012938/LLM_visualglm_model/\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n"
     ]
    }
   ],
   "source": [
    "# we plug in the appropriate model location into our `serving.properties` file based on the region in which this notebook is running\n",
    "template = jinja_env.from_string(Path(\"LLM_visualglm_deploy_code/serving.properties\").open().read())\n",
    "Path(\"LLM_visualglm_deploy_code/serving.properties\").open(\"w\").write(\n",
    "    template.render(s3url=s3url)\n",
    ")\n",
    "!pygmentize LLM_visualglm_deploy_code/serving.properties | cat -n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa95a6b6-fde1-4f2f-92aa-e3b255cf1e7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a9f1dce7-8f41-4b2e-a6b6-179c3cdc21be",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM_visualglm_deploy_code/\n",
      "LLM_visualglm_deploy_code/serving.properties\n",
      "LLM_visualglm_deploy_code/requirements.txt\n",
      "LLM_visualglm_deploy_code/model.py\n"
     ]
    }
   ],
   "source": [
    "!rm model.tar.gz\n",
    "!cd LLM_visualglm_deploy_code && rm -rf \".ipynb_checkpoints\"\n",
    "!tar czvf model.tar.gz LLM_visualglm_deploy_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ba089782-5b2c-4b1a-bd31-70ff5e8d68b8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S3 Code or Model tar ball uploaded to --- > s3://sagemaker-us-west-2-691188012938/LLM_visualglm_deploy_code/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "s3_code_artifact = sess.upload_data(\"model.tar.gz\", bucket, s3_code_prefix)\n",
    "print(f\"S3 Code or Model tar ball uploaded to --- > {s3_code_artifact}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f8d87b-1986-4d35-acc7-445b2f46cb10",
   "metadata": {},
   "source": [
    "### 1.3 创建模型 & 创建endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1b736cdb-1430-4eb1-a04c-8812f2e908dc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "visualglm-2023-11-10-01-54-20-117\n",
      "Image going to be used is ---- > 763104351884.dkr.ecr.us-west-2.amazonaws.com/djl-inference:0.22.1-deepspeed0.9.2-cu118\n",
      "Created Model: arn:aws:sagemaker:us-west-2:691188012938:model/visualglm-2023-11-10-01-54-20-117\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.utils import name_from_base\n",
    "import boto3\n",
    "\n",
    "model_name = name_from_base(f\"visualglm\") # Append a timestamp to the provided string\n",
    "print(model_name)\n",
    "print(f\"Image going to be used is ---- > {inference_image_uri}\")\n",
    "\n",
    "create_model_response = sm_client.create_model(\n",
    "    ModelName=model_name,\n",
    "    ExecutionRoleArn=role,\n",
    "    PrimaryContainer={\n",
    "        \"Image\": inference_image_uri,\n",
    "        \"ModelDataUrl\": s3_code_artifact\n",
    "    },\n",
    "    \n",
    ")\n",
    "model_arn = create_model_response[\"ModelArn\"]\n",
    "\n",
    "print(f\"Created Model: {model_arn}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "85794eff-c9b7-44fd-85fa-a3ec40416e8e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'EndpointConfigArn': 'arn:aws:sagemaker:us-west-2:691188012938:endpoint-config/visualglm-2023-11-10-01-54-20-117-config',\n",
       " 'ResponseMetadata': {'RequestId': 'f5917659-eb55-4f87-9d97-14826eaf8cb9',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': 'f5917659-eb55-4f87-9d97-14826eaf8cb9',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '121',\n",
       "   'date': 'Fri, 10 Nov 2023 01:54:20 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endpoint_config_name = f\"{model_name}-config\"\n",
    "endpoint_name = f\"{model_name}-endpoint\"\n",
    "\n",
    "#Note: ml.g4dn.2xlarge 也可以选择\n",
    "endpoint_config_response = sm_client.create_endpoint_config(\n",
    "    EndpointConfigName=endpoint_config_name,\n",
    "    ProductionVariants=[\n",
    "        {\n",
    "            \"VariantName\": \"variant1\",\n",
    "            \"ModelName\": model_name,\n",
    "            \"InstanceType\": \"ml.g5.2xlarge\",\n",
    "            \"InitialInstanceCount\": 1,\n",
    "            \"ContainerStartupHealthCheckTimeoutInSeconds\": 10*60,\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "endpoint_config_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3d3bd72c-eddc-40d2-8805-372551efb1b6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created Endpoint: arn:aws:sagemaker:us-west-2:691188012938:endpoint/visualglm-2023-11-10-01-54-20-117-endpoint\n"
     ]
    }
   ],
   "source": [
    "create_endpoint_response = sm_client.create_endpoint(\n",
    "    EndpointName=f\"{endpoint_name}\", EndpointConfigName=endpoint_config_name\n",
    ")\n",
    "print(f\"Created Endpoint: {create_endpoint_response['EndpointArn']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ae08ecbc-4141-401f-b60e-d76bf9c6900e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: InService\n",
      "Arn: arn:aws:sagemaker:us-west-2:691188012938:endpoint/visualglm-2023-11-10-01-54-20-117-endpoint\n",
      "Status: InService\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "resp = sm_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "status = resp[\"EndpointStatus\"]\n",
    "print(\"Status: \" + status)\n",
    "\n",
    "while status == \"Creating\":\n",
    "    time.sleep(60)\n",
    "    resp = sm_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "    status = resp[\"EndpointStatus\"]\n",
    "    print(\"Status: \" + status)\n",
    "\n",
    "print(\"Arn: \" + resp[\"EndpointArn\"])\n",
    "print(\"Status: \" + status)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59fe36e-b045-4786-81c4-5f5a14e52e2b",
   "metadata": {},
   "source": [
    "## 2.生成关键帧的内容描述"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919a8add-0b21-4ba3-83f4-ea976fe5ce23",
   "metadata": {},
   "source": [
    "### 2.1 对视频抽帧并上传至S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "99e116f0-9231-460e-9b7c-a600d20c85d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (4.8.1.78)\n",
      "Requirement already satisfied: numpy>=1.21.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from opencv-python) (1.26.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "269aacb2-3cba-42e3-8a40-213ae2a62179",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import sagemaker\n",
    "from sagemaker import image_uris\n",
    "import boto3\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d60c2e31-2728-4b77-92ce-229ff952f8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_frame_prefix = 'videokeyframe'\n",
    "video_name='little_kitten_playing_his_toy_mouse'\n",
    "video_path='../video/5/'+video_name+'.mp4'\n",
    "frame_path='../video_frame/5/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b65e5983-b4ca-4b22-9c91-fd13efb9a09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_and_upload_img(video_path,frame_path):\n",
    "    frame_list=[]\n",
    "    vc = cv2.VideoCapture(video_path)  # 读入视频文件\n",
    "    c = 1\n",
    "    if vc.isOpened():  # 判断是否正常打开\n",
    "        rval, frame = vc.read()\n",
    "    else:\n",
    "        rval = False\n",
    "    timeF = 35  # 视频帧计数间隔频率\n",
    "    while rval:  # 循环读取视频帧\n",
    "        rval, frame = vc.read()\n",
    "        if (c % timeF == 0):  # 每隔timeF帧进行存储操作\n",
    "            if frame is not None:\n",
    "                #timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "                filename = \"Frame1\"+str(c)+'.jpg'\n",
    "                cv2.imwrite(frame_path + filename, frame)\n",
    "                frame_list.append(filename)\n",
    "        c = c + 1\n",
    "        cv2.waitKey(10)\n",
    "    vc.release()\n",
    "    return frame_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "08a80e3d-21d2-4be8-baa6-b0f6b4cb7656",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_list= extract_and_upload_img(video_path,frame_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "281ad20d-e61b-43db-82eb-1a3e69ac87c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Frame135.jpg', 'Frame170.jpg', 'Frame1105.jpg', 'Frame1140.jpg', 'Frame1175.jpg', 'Frame1210.jpg', 'Frame1245.jpg', 'Frame1280.jpg', 'Frame1315.jpg']\n"
     ]
    }
   ],
   "source": [
    "print(frame_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8d8983d5-9eb2-4b48-9820-7a8bbb2c9923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: ../video_frame/5/Frame1105.jpg to s3://sagemaker-us-west-2-691188012938/videokeyframe/Frame1105.jpg\n",
      "upload: ../video_frame/5/Frame1245.jpg to s3://sagemaker-us-west-2-691188012938/videokeyframe/Frame1245.jpg\n",
      "upload: ../video_frame/5/Frame1175.jpg to s3://sagemaker-us-west-2-691188012938/videokeyframe/Frame1175.jpg\n",
      "upload: ../video_frame/5/Frame170.jpg to s3://sagemaker-us-west-2-691188012938/videokeyframe/Frame170.jpg\n",
      "upload: ../video_frame/5/Frame1315.jpg to s3://sagemaker-us-west-2-691188012938/videokeyframe/Frame1315.jpg\n",
      "upload: ../video_frame/5/Frame1280.jpg to s3://sagemaker-us-west-2-691188012938/videokeyframe/Frame1280.jpg\n",
      "upload: ../video_frame/5/Frame1210.jpg to s3://sagemaker-us-west-2-691188012938/videokeyframe/Frame1210.jpg\n",
      "upload: ../video_frame/5/Frame1140.jpg to s3://sagemaker-us-west-2-691188012938/videokeyframe/Frame1140.jpg\n",
      "upload: ../video_frame/5/Frame135.jpg to s3://sagemaker-us-west-2-691188012938/videokeyframe/Frame135.jpg\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp --recursive {frame_path} s3://{bucket}/{s3_frame_prefix}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa5a970-e049-4684-8184-650210564d06",
   "metadata": {},
   "source": [
    "### 2.2 利用VLM 产生内容描述"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d85e2d6e-eed6-44af-b3b6-c6defa1f0570",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "def generate_s3_image_url(bucket_name, key, expiration=3600):\n",
    "    s3_client = boto3.client('s3')\n",
    "    url = s3_client.generate_presigned_url(\n",
    "        'get_object',\n",
    "         Params={'Bucket': bucket_name, 'Key': key},\n",
    "         ExpiresIn=expiration\n",
    "    )\n",
    "    return url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a2c08a6b-f173-4f2f-bd24-dddb1d16b057",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "history = []\n",
    "prompt = \"请描述这张图片的内容\"\n",
    "parameters = {\n",
    "  \"max_length\": 2000,\n",
    "  \"temperature\": 0.1,\n",
    "  \"top_p\":1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "196a9467-88a2-4cb0-9701-e9687e6ed7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "content_result_list=[]\n",
    "for item in frame_list:\n",
    "    imgurl=str(bucket)+'/'+str(s3_frame_prefix)+'/'+item\n",
    "    bucket,imgobj = imgurl.split('/',1)\n",
    "    image_path = generate_s3_image_url(bucket,imgobj)\n",
    "    #print(image_path)\n",
    "    response_model = smr_client.invoke_endpoint(\n",
    "            EndpointName=endpoint_name,\n",
    "            Body=json.dumps(\n",
    "            {\n",
    "                \"inputs\": prompt,\n",
    "                \"image\":image_path,\n",
    "                \"parameters\": parameters,\n",
    "                \"history\" : []\n",
    "            }\n",
    "            ),\n",
    "            ContentType=\"application/json\",\n",
    "        )\n",
    "\n",
    "    result=response_model['Body'].read().decode('utf8')\n",
    "    content_result_list.append(result)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7442711c-d192-4566-b1ca-9c526ef296c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['{\\n  \"outputs\":\"这张照片展示了一只橙色的小猫，它站在一张沙发上。这只猫正在玩一个玩具球或毛绒玩具。此外，它还有一只猫薄荷的气味。这使图像有趣而生动。小猫和它的玩具的存在表明这个场景是一个有趣的家庭环境的一部分。\"\\n}', '{\\n  \"outputs\":\"这张照片显示一只橙色的小猫坐在一张沙发上，手里拿着一个玩具。这只猫正在玩耍或探索沙发周围的空间。它似乎非常好奇和兴奋，可能是在玩球或其他游戏。这个场景展示了小猫的好奇心、活力和对周围物体的兴趣。\"\\n}', '{\\n  \"outputs\":\"这张照片描绘了一只橙色的小猫，它站在一张沙发上，手里拿着一个玩具。这只猫似乎正在玩耍或探索这个玩具。此外，在沙发旁边有一个枕头和一本杂志，这表明这个地方可能是一个舒适的休息场所。照片展示了猫咪玩耍、探索和与周围环境互动的场景。\"\\n}', '{\\n  \"outputs\":\"这张照片展示了一只橙色的小猫，它正在沙发上玩耍。这只猫似乎很活跃和好奇，在玩玩具或探索家具时表现出了活力。此外，它还表现出一种快乐的情绪，因为它被一个有趣的东西吸引了注意力。这种活泼和好奇心的场景为照片增添了一些趣味感。\"\\n}', '{\\n  \"outputs\":\"这张照片显示一只橙色的小猫，可能是长毛猫或虎斑猫，躺在一张沙发上。这只猫似乎正在玩耍或者移动，它的尾巴在沙发和枕头之间摆动着。背景中有一只枕头，表明有其他人的存在，可能包括主人或其他家庭成员。\"\\n}', '{\\n  \"outputs\":\"这张照片显示一只橙色的小猫，很可能是一只小猫咪或小橘猫，在一张沙发上玩耍。它似乎正在用爪子抓住沙发垫子上的一块布。这只猫可能正在探索家具表面、沙发垫子或其他物体，可能是寻找玩具或者与主人互动。\"\\n}', '{\\n  \"outputs\":\"这张照片展示了一只橙色的小猫，它站在一张沙发上，用爪子抓沙发。这只猫似乎正在玩耍或探索家具和物品。这场景非常有趣，因为小猫在玩球时表现出好奇、兴奋和活跃的精神。背景中的枕头为这个场景增添了温馨的氛围。\"\\n}', '{\\n  \"outputs\":\"这张照片展示了一只橙色的小猫，它站在一张沙发上。这只猫正在用爪子抓住沙发或家具上的一块布来玩耍。这个场景表明这只猫可能非常活跃和好奇，可能是在探索周围的环境或寻找玩具。此外，这只猫似乎很放松，因为它没有表现出任何紧张、警惕或不安全感的迹象。\"\\n}', '{\\n  \"outputs\":\"这张照片显示一只橙色的小猫躺在一张沙发上，手里拿着一个猫玩具。这只小猫似乎正在玩耍或嬉戏，可能是在探索沙发或其他物体。它的存在和动作表明这个场景是一个有趣的、充满活力的环境。小猫还表现出好奇和活跃的迹象，这可能会吸引其他动物的注意力并引起注意。\"\\n}']\n"
     ]
    }
   ],
   "source": [
    "print(content_result_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1aa35dd-5b61-4aea-850e-188d1dcc5847",
   "metadata": {},
   "source": [
    "## 3.使用Bedrock Claude进行不同任务"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "fcb642df-a529-49b4-9fcc-5dc7b27b1513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (0.0.330)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langchain) (2.0.23)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langchain) (3.8.6)\n",
      "Requirement already satisfied: anyio<4.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langchain) (3.7.1)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langchain) (4.0.3)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langchain) (0.6.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langchain) (1.33)\n",
      "Requirement already satisfied: langsmith<0.1.0,>=0.0.52 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langchain) (0.0.57)\n",
      "Requirement already satisfied: numpy<2,>=1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langchain) (1.26.1)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langchain) (2.4.2)\n",
      "Requirement already satisfied: requests<3,>=2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langchain) (8.2.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (3.3.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: idna>=2.8 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from anyio<4.0->langchain) (3.4)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from anyio<4.0->langchain) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from anyio<4.0->langchain) (1.1.3)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.20.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.10.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (2.10.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (4.8.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests<3,>=2->langchain) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2023.7.22)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.1)\n",
      "Requirement already satisfied: packaging>=17.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.7,>=0.5.7->langchain) (21.3)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from packaging>=17.0->marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.7,>=0.5.7->langchain) (3.1.1)\n",
      "Requirement already satisfied: anthropic in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (0.5.0)\n",
      "Requirement already satisfied: anyio<4,>=3.5.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from anthropic) (3.7.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from anthropic) (1.8.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from anthropic) (0.25.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from anthropic) (2.4.2)\n",
      "Requirement already satisfied: tokenizers>=0.13.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from anthropic) (0.14.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from anthropic) (4.8.0)\n",
      "Requirement already satisfied: idna>=2.8 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from anyio<4,>=3.5.0->anthropic) (3.4)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from anyio<4,>=3.5.0->anthropic) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from anyio<4,>=3.5.0->anthropic) (1.1.3)\n",
      "Requirement already satisfied: certifi in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from httpx<1,>=0.23.0->anthropic) (2023.7.22)\n",
      "Requirement already satisfied: httpcore in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from httpx<1,>=0.23.0->anthropic) (1.0.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->anthropic) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.10.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->anthropic) (2.10.1)\n",
      "Requirement already satisfied: huggingface_hub<0.18,>=0.16.4 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from tokenizers>=0.13.0->anthropic) (0.17.3)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface_hub<0.18,>=0.16.4->tokenizers>=0.13.0->anthropic) (3.12.4)\n",
      "Requirement already satisfied: fsspec in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface_hub<0.18,>=0.16.4->tokenizers>=0.13.0->anthropic) (2023.10.0)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface_hub<0.18,>=0.16.4->tokenizers>=0.13.0->anthropic) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface_hub<0.18,>=0.16.4->tokenizers>=0.13.0->anthropic) (4.66.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface_hub<0.18,>=0.16.4->tokenizers>=0.13.0->anthropic) (6.0.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface_hub<0.18,>=0.16.4->tokenizers>=0.13.0->anthropic) (21.3)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from httpcore->httpx<1,>=0.23.0->anthropic) (0.14.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from packaging>=20.9->huggingface_hub<0.18,>=0.16.4->tokenizers>=0.13.0->anthropic) (3.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->huggingface_hub<0.18,>=0.16.4->tokenizers>=0.13.0->anthropic) (3.3.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->huggingface_hub<0.18,>=0.16.4->tokenizers>=0.13.0->anthropic) (1.26.18)\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain\n",
    "!pip install anthropic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f8127acf-c4c7-4d98-8f56-bf37504ba6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms.bedrock import Bedrock\n",
    "from langchain import LLMChain, PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4cdf5639-33c6-4b9f-92ec-a76fcc9a653c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create new client\n",
      "  Using region: None\n",
      "boto3 Bedrock client successfully created!\n",
      "bedrock-runtime(https://bedrock-runtime.us-west-2.amazonaws.com)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import boto3\n",
    "import botocore\n",
    "\n",
    "from utils import bedrock\n",
    "\n",
    "boto3_bedrock = bedrock.get_bedrock_client()\n",
    "\n",
    "#boto3_bedrock.list_foundation_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f639ff8c-3e37-4562-80f5-051b64234e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms.bedrock import Bedrock\n",
    "\n",
    "inference_modifier = {'max_tokens_to_sample':4096, \n",
    "                      \"temperature\":0.5,\n",
    "                      \"top_k\":250,\n",
    "                      \"top_p\":1,\n",
    "                      \"stop_sequences\": [\"\\n\\nHuman\"]\n",
    "                     }\n",
    "\n",
    "textgen_llm = Bedrock(model_id = \"anthropic.claude-v2\",\n",
    "                    client = boto3_bedrock, \n",
    "                    model_kwargs = inference_modifier \n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8846da-ccc5-412f-97cf-df73a2c9d8ce",
   "metadata": {},
   "source": [
    "### 3.1 视频摘要（Video Summary）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "acfb5d62-2164-420c-ac7b-c6e4f71cff91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our prompt has 1371 tokens\n"
     ]
    }
   ],
   "source": [
    "with open('./utils/video_summary.txt', 'r', encoding=\"utf-8\") as task:\n",
    "    lines = task.readlines()\n",
    "    multi_var_prompt = PromptTemplate(\n",
    "    input_variables=[\"input\"], \n",
    "    template=\"\"\"\n",
    "\n",
    "        Human: {}\n",
    "\n",
    "        Assistant: ok \"\"\".format(lines)\n",
    "        )\n",
    "    prompt = multi_var_prompt.format(input=str(content_result_list))\n",
    "    num_tokens = textgen_llm.get_num_tokens(prompt)\n",
    "    print(f\"Our prompt has {num_tokens} tokens\")\n",
    "    \n",
    "    response = textgen_llm(prompt)\n",
    "    content = response[response.index('\\n')+1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d46ef832-6a2a-4894-b8c5-e54c1a02f49a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "此视频显示一只橙色的小猫,它在一张沙发上玩耍。这只猫看起来很好奇和活跃,它在探索周围的环境和玩具。有时它站着,有时它躺着,但总是在动来动去。它用爪子抓住沙发垫或其他物体。有一个枕头和一本杂志放在沙发旁边。这只小猫的玩耍和探索为这个家庭场景增添了生机。整个视频描绘了一只活跃好动的小猫的日常生活片段。\n"
     ]
    }
   ],
   "source": [
    "print(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a86170-e4cf-4dc7-9a23-c657245db0ef",
   "metadata": {},
   "source": [
    "### 3.2 社交圈文案生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "56b2997e-946f-4802-951f-2a90ebaa3f2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our prompt has 1577 tokens\n"
     ]
    }
   ],
   "source": [
    "with open('./utils/social_media_post.txt', 'r', encoding=\"utf-8\") as task:\n",
    "    lines = task.readlines()\n",
    "    multi_var_prompt = PromptTemplate(\n",
    "    input_variables=[\"input\"], \n",
    "    template=\"\"\"\n",
    "\n",
    "        Human: {}\n",
    "\n",
    "        Assistant: ok \"\"\".format(lines)\n",
    "        )\n",
    "    prompt = multi_var_prompt.format(input=str(content_result_list))\n",
    "    num_tokens = textgen_llm.get_num_tokens(prompt)\n",
    "    print(f\"Our prompt has {num_tokens} tokens\")\n",
    "    \n",
    "    response = textgen_llm(prompt)\n",
    "    content = response[response.index('\\n')+1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e7ee8d70-aaf2-4afe-bd86-35d13f6ef1f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "视频里有一只橙色的小猫咪,它看起来非常活泼可爱。😍它先是站在沙发上,一边玩着一个小球一边闻着猫薄荷。然后它坐在沙发上,两只小短腿耸拉着,一只爪子拿着一个玩具在玩。接着它站起来,用爪子抓着沙发玩耍。最后它躺在沙发上,抱着一个猫玩具滚来滚去。\n",
      "\n",
      "这只小猫咪看起来非常开心和充满活力!🤩它好奇地探索着周围的环境,玩着各种玩具,样子非常可爱。我看到这个视频时,心里暖暖的,忍不住想逗它玩。😆\n",
      "\n",
      "希望这个视频也能让你们开心一下!记得给我留言告诉我你们的感受哦!💬\n"
     ]
    }
   ],
   "source": [
    "print(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca61541-b5af-4270-9811-6a638891ffc1",
   "metadata": {},
   "source": [
    "### 3.3 基于图像的问答"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "05911232-f269-4354-ae48-9b122e4a56f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our prompt has 1350 tokens\n"
     ]
    }
   ],
   "source": [
    "with open('./utils/VQA.txt', 'r', encoding=\"utf-8\") as task:\n",
    "    lines = task.readlines()\n",
    "    multi_var_prompt = PromptTemplate(\n",
    "    input_variables=[\"input\",\"question\"], \n",
    "    template=\"\"\"\n",
    "\n",
    "        Human: {}\n",
    "\n",
    "        Assistant:  \"\"\".format(lines)\n",
    "        )\n",
    "    prompt = multi_var_prompt.format(input=str(content_result_list),question=\"我的杂志放在了哪里?\")\n",
    "    num_tokens = textgen_llm.get_num_tokens(prompt)\n",
    "    print(f\"Our prompt has {num_tokens} tokens\")\n",
    "    \n",
    "    response = textgen_llm(prompt)\n",
    "    content = response[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "86a99052-0e1d-40ba-9e4e-7cd897f9c2c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 沙发旁边有一本杂志。\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40236fb-c1d5-4ce0-b629-76184c4e3aaa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.g4dn.2xlarge",
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
