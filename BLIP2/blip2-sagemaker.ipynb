{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d942e395-2ebf-400d-8c0d-aaed37da9672",
   "metadata": {},
   "source": [
    "## Deploy BLIP2 Endpoint on SageMaker\n",
    "\n",
    "In this notebook, we will deploy a BLIP2 endpoint with DJLServing container image.\n",
    "\n",
    "This notebook has been tested within SageMaker Studio Notebook environment Python3 Data Science environment. \n",
    "\n",
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cce6d006-3e03-4773-810f-1e593c757b57",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "awscli 1.29.75 requires botocore==1.31.75, but you have botocore 1.31.85 which is incompatible.\n",
      "tokenizers 0.14.1 requires huggingface_hub<0.18,>=0.16.4, but you have huggingface-hub 0.19.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install sagemaker boto3 huggingface_hub --upgrade --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f1ecae5-822a-487c-a58f-3a6f364eb508",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "import jinja2\n",
    "from sagemaker import image_uris\n",
    "import boto3\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "from pathlib import Path\n",
    "import json\n",
    "import base64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bdfc4d04-25f9-4c10-aadf-a76b57ba8cbe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "role = sagemaker.get_execution_role()  # execution role for the endpoint\n",
    "sess = sagemaker.session.Session()  # sagemaker session for interacting with different AWS APIs\n",
    "bucket = sess.default_bucket()  # bucket to house artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f55e63f5-ab27-4eb1-81ca-2e166483f1a2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrained model will be uploaded to ---- > s3://sagemaker-us-west-2-691188012938/model_blip2/\n"
     ]
    }
   ],
   "source": [
    "model_bucket = sess.default_bucket()  # bucket to house artifacts\n",
    "s3_code_prefix = \"blip2\"  # folder within bucket where code artifact will go\n",
    "s3_model_prefix = \"model_blip2\"  # folder within bucket where code artifact will go\n",
    "region = sess._region_name\n",
    "account_id = sess.account_id()\n",
    "\n",
    "s3_client = boto3.client(\"s3\")\n",
    "sm_client = boto3.client(\"sagemaker\")\n",
    "smr_client = boto3.client(\"sagemaker-runtime\")\n",
    "\n",
    "jinja_env = jinja2.Environment()\n",
    "\n",
    "# define a variable to contain the s3url of the location that has the model\n",
    "pretrained_model_location = f\"s3://{model_bucket}/{s3_model_prefix}/\"\n",
    "print(f\"Pretrained model will be uploaded to ---- > {pretrained_model_location}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb7499bb-2944-4bdc-95a3-fd3ec3dee465",
   "metadata": {},
   "source": [
    "## Prepare inference script and container image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47ee875d-91d0-4ab8-901f-0a0bce95652b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'763104351884.dkr.ecr.us-west-2.amazonaws.com/djl-inference:0.22.1-deepspeed0.9.2-cu118'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference_image_uri = image_uris.retrieve(\n",
    "    framework=\"djl-deepspeed\", region=sess.boto_session.region_name, version=\"0.22.1\"\n",
    ")\n",
    "inference_image_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53680769-4e06-4270-b376-eb3d5a71f3ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "blip_model_version = \"blip2-flan-t5-xl\"\n",
    "model_names = {\n",
    "    \"caption_model_name\": blip_model_version, #@param [\"blip-base\", \"blip-large\", \"blip2-flan-t5-xl\"]\n",
    "}\n",
    "with open(\"blip2/model_name.json\",'w') as file:\n",
    "    json.dump(model_names, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d1c3412-1df2-49d2-9cd0-31b2326389c4",
   "metadata": {},
   "source": [
    "In this notebook, we will provide two ways to load the model when deploying to an endpoint.\n",
    "- Directly load from Hugging Face \n",
    "- Store the model artifacts on S3 and load the model directly from S3\n",
    "\n",
    "The [Large Model Inference (LMI)](https://docs.aws.amazon.com/sagemaker/latest/dg/large-model-inference-dlc.html) container uses [s5cmd](https://github.com/peak/s5cmd) to download data from S3 which significantly reduces the speed when loading model during deployment. Therefore, we recommend to load the model from S3 by following the below section to download the model from Hugging Face and upload the model on S3. \n",
    "\n",
    "If you choose to load the model directly from Hugging Face during model deployment, you can skip the below section and jump to the section to **prepare the model tarbal file and upload to S3**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb7102d7-58e5-449e-8dc3-eb1bf76da79a",
   "metadata": {},
   "source": [
    "### [OPTIONAL] Download the model from Hugging Face and upload the model artifacts on Amazon S3\n",
    "If you intend to download your copy of the model and upload it to a s3 location in your AWS account, please follow the below steps, else you can skip to the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5aaf38b0-5006-40e0-95be-8b1bbea48ce9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16a6f7e14f2e43b39584d51ebcc2c930",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 9 files:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec4eb84e667742e595fd1202a01e5364",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model-00001-of-00002.bin:   0%|          | 0.00/9.44G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "395d76a3f0e24b77b631032cb9abeaa2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model-00002-of-00002.bin:   0%|          | 0.00/6.33G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07d05672825f4351af9c2af7162a6f4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d17eeddb16ee433e9a3f56b18dec0956",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)d4d1c37753c7e9c05a443a226614/config.json:   0%|          | 0.00/7.68k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "413bfda2464c4b3db417974ea06952c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)e9c05a443a226614/special_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ccf3f3a975b4022923e02ffb0d8e034",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)9c05a443a226614/preprocessor_config.json:   0%|          | 0.00/432 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a547b73121a3412897126ba7e2d09c34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)a443a226614/pytorch_model.bin.index.json:   0%|          | 0.00/128k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7eeee75b9594102b30252622af16045",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)1c37753c7e9c05a443a226614/tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1609a1c3474d4bb59057e7adf1a357b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)c7e9c05a443a226614/tokenizer_config.json:   0%|          | 0.00/2.54k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import snapshot_download\n",
    "from pathlib import Path\n",
    "\n",
    "CAPTION_MODELS = {\n",
    "    'blip-base': 'Salesforce/blip-image-captioning-base',   # 990MB\n",
    "    'blip-large': 'Salesforce/blip-image-captioning-large', # 1.9GB\n",
    "    'blip2-2.7b': 'Salesforce/blip2-opt-2.7b',              # 15.5GB\n",
    "    'blip2-flan-t5-xl': 'Salesforce/blip2-flan-t5-xl',      # 15.77GB\n",
    "}\n",
    "\n",
    "# - This will download the model into the current directory where ever the jupyter notebook is running\n",
    "local_model_path = Path(\"./blip2-model\")\n",
    "local_model_path.mkdir(exist_ok=True)\n",
    "model_name = CAPTION_MODELS[blip_model_version]\n",
    "# Only download pytorch checkpoint files\n",
    "allow_patterns = [\"*.json\", \"*.pt\", \"*.bin\", \"*.txt\", \"*.model\"]\n",
    "\n",
    "# - Leverage the snapshot library to donload the model since the model is stored in repository using LFS\n",
    "model_download_path = snapshot_download(\n",
    "    repo_id=model_name,\n",
    "    cache_dir=local_model_path,\n",
    "    allow_patterns=allow_patterns,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b2be006-576f-4799-a16c-f26a9da66b80",
   "metadata": {},
   "source": [
    "Please make sure the file is downloaded correctly by checking the files exist in the newly created folder `blip2-model/models--Salesforce--<model-name>/snapshots/...` before running the below cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ec0aeb4-9e76-4b4b-ab69-f3aacecb32b3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model uploaded to --- > s3://sagemaker-us-west-2-691188012938/model_blip2\n",
      "We will set option.s3url=s3://sagemaker-us-west-2-691188012938/model_blip2\n"
     ]
    }
   ],
   "source": [
    "# upload the model artifacts to s3\n",
    "model_artifact = sess.upload_data(path=model_download_path, key_prefix=s3_model_prefix)\n",
    "print(f\"Model uploaded to --- > {model_artifact}\")\n",
    "print(f\"We will set option.s3url={model_artifact}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "79b8532e-ee56-4596-a55a-0666baac42a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!rm -rf {local_model_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7823c93a-4bc8-44f9-b4c2-b8f137e9c46d",
   "metadata": {},
   "source": [
    "SageMaker Large Model Inference containers can be used to host models without providing your own inference code. This is extremely useful when there is no custom pre-processing of the input data or post-processing of the model's predictions.\n",
    "\n",
    "However, in this notebook, we demonstrate how to deploy a model with custom inference code.\n",
    "\n",
    "SageMaker needs the model artifacts to be in a Tarball format. In this example, we provide the following files - `serving.properties`, `model.py`, and `requirements.txt`.\n",
    "- `serving.properties` is the configuration file that can be used to indicate to DJL Serving which model parallelization and inference optimization libraries you would like to use. Depending on your need, you can set the appropriate configuration. For more details on the configuration options and an exhaustive list, you can refer the [documentation](https://docs.aws.amazon.com/sagemaker/latest/dg/realtime-endpoints-large-model-configuration.html).\n",
    "- `model.py` is the script handles any requests for serving.\n",
    "- `requirements.txt` is the text file containing any additional pip wheel need to install. \n",
    "\n",
    "If you want to download the model from huggingface.co, you can set option.model_id. The model id of a pretrained model hosted inside a model repository on huggingface.co (https://huggingface.co/models). The container uses this model id to download the corresponding model repository on huggingface.co. If you set the model_id to a s3 url, the DJL will download the model artifacts from s3 and swap the model_id to the actual location of the model artifacts. In your script, you can point to this value to load the pre-trained model.\n",
    "- `option.tensor_parallel_degree`: Set to the number of GPU devices over which the model needs to be partitioned. This parameter also controls the number of workers per model which will be started up when DJL serving runs. As an example if we have a 8 GPU machine, and we are creating 8 partitions then we will have 1 worker per model to serve the requests.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "001f38dc-1d75-4167-a4f9-4518024c7bef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting blip2/serving.properties\n"
     ]
    }
   ],
   "source": [
    "%%writefile blip2/serving.properties\n",
    "engine = Python\n",
    "option.tensor_parallel_degree = 1\n",
    "option.model_id = {{s3url}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "19eabd92-12d6-4f05-90fe-219c290e0b05",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1\t\u001b[36mengine\u001b[39;49;00m\u001b[37m \u001b[39;49;00m=\u001b[37m \u001b[39;49;00m\u001b[33mPython\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "     2\t\u001b[36moption.tensor_parallel_degree\u001b[39;49;00m\u001b[37m \u001b[39;49;00m=\u001b[37m \u001b[39;49;00m\u001b[33m1\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "     3\t\u001b[36moption.model_id\u001b[39;49;00m\u001b[37m \u001b[39;49;00m=\u001b[37m \u001b[39;49;00m\u001b[33ms3://sagemaker-us-west-2-691188012938/model_blip2/\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n"
     ]
    }
   ],
   "source": [
    "# we plug in the appropriate model location into our `serving.properties` file based on the region in which this notebook is running\n",
    "template = jinja_env.from_string(Path(\"blip2/serving.properties\").open().read())\n",
    "Path(\"blip2/serving.properties\").open(\"w\").write(\n",
    "    template.render(s3url=pretrained_model_location)\n",
    ")\n",
    "!pygmentize blip2/serving.properties | cat -n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b31c66dd-ee1d-4cc5-961b-0b9b063c4f22",
   "metadata": {},
   "source": [
    "## Prepare the model tarball file and upload to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eeae8bc2-f3c9-4174-8ebe-3230efaa72a1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blip2/\n",
      "blip2/.ipynb_checkpoints/\n",
      "blip2/.ipynb_checkpoints/model-checkpoint.py\n",
      "blip2/.ipynb_checkpoints/serving-checkpoint.properties\n",
      "blip2/.ipynb_checkpoints/requirements-checkpoint.txt\n",
      "blip2/serving.properties\n",
      "blip2/requirements.txt\n",
      "blip2/model_name.json\n",
      "blip2/model.py\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "tar czvf model.tar.gz blip2/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8ec0e818-1a0a-4d5a-b86e-f06d19eaa0e7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S3 Code or Model tar ball uploaded to --- > s3://sagemaker-us-west-2-691188012938/blip2/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "s3_code_artifact = sess.upload_data(\"model.tar.gz\", bucket, s3_code_prefix)\n",
    "print(f\"S3 Code or Model tar ball uploaded to --- > {s3_code_artifact}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521fb573-b45c-4bbc-8f2e-0e46bff6f14a",
   "metadata": {},
   "source": [
    "## Deploy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "304c8205-c549-4f09-abab-7525047fab39",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.model import Model\n",
    "from sagemaker.utils import name_from_base\n",
    "\n",
    "model_name = name_from_base(blip_model_version)\n",
    "model = Model(\n",
    "    image_uri=inference_image_uri,\n",
    "    model_data=s3_code_artifact,\n",
    "    role=role,\n",
    "    name=model_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52fc1232-8d70-4ea1-a617-d43fb4eaab3c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n",
      "------------"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "endpoint_name = \"endpoint-\" + model_name\n",
    "model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=\"ml.g5.2xlarge\",\n",
    "    endpoint_name=endpoint_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b1b633-2839-42c4-a4e0-65568e8bd302",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%store endpoint_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2494405e-06d2-476a-af72-380879b8e24d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6600b37c-0ba4-491c-bcf1-fd1ab9e3ae94",
   "metadata": {},
   "source": [
    "## 2.生成关键帧的内容描述"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e66a846-75c5-4c4f-8be8-bfdcf4df0570",
   "metadata": {},
   "source": [
    "## 2.1 对视频抽帧并上传至S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b495db0b-0338-401b-9ae9-40a3ea4a2dfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (4.8.1.78)\n",
      "Requirement already satisfied: numpy>=1.21.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from opencv-python) (1.26.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "96015607-8349-4522-bf6e-a286b7b44555",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import sagemaker\n",
    "from sagemaker import image_uris\n",
    "import boto3\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e906cd48-6e09-4de3-b325-ca5ce933ed0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_frame_prefix = 'videokeyframe'\n",
    "video_name='bird_going_inside_a_bird_house'\n",
    "video_path='../video/4/'+video_name+'.mp4'\n",
    "frame_path='../video_frame/4/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "718e476a-c343-4b41-98e8-10099a180e63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../video/4/bird_going_inside_a_bird_house.mp4\n"
     ]
    }
   ],
   "source": [
    "print(video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9beebcf1-2668-4980-a761-116344ab6c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_and_upload_img(video_path,frame_path,video_name):\n",
    "    frame_list=[]\n",
    "    vc = cv2.VideoCapture(video_path)  # 读入视频文件\n",
    "    c = 1\n",
    "    if vc.isOpened():  # 判断是否正常打开\n",
    "        rval, frame = vc.read()\n",
    "        print('yes')\n",
    "    else:\n",
    "        rval = False\n",
    "    timeF = 35  # 视频帧计数间隔频率\n",
    "    while rval:  # 循环读取视频帧\n",
    "        rval, frame = vc.read()\n",
    "        if (c % timeF == 0):  # 每隔timeF帧进行存储操作\n",
    "            if frame is not None:\n",
    "                #timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "                filename = video_name+str(c)+'.jpg'\n",
    "                cv2.imwrite(frame_path + filename, frame)\n",
    "                frame_list.append(filename)\n",
    "        c = c + 1\n",
    "        cv2.waitKey(10)\n",
    "    vc.release()\n",
    "    return frame_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "248c3597-5f1a-4b1b-b5c1-dd18a25fe817",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes\n"
     ]
    }
   ],
   "source": [
    "frame_list= extract_and_upload_img(video_path,frame_path,video_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "2bee3813-e704-4c81-9472-efb1d2b97a0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bird_going_inside_a_bird_house35.jpg', 'bird_going_inside_a_bird_house70.jpg', 'bird_going_inside_a_bird_house105.jpg', 'bird_going_inside_a_bird_house140.jpg', 'bird_going_inside_a_bird_house175.jpg', 'bird_going_inside_a_bird_house210.jpg', 'bird_going_inside_a_bird_house245.jpg', 'bird_going_inside_a_bird_house280.jpg', 'bird_going_inside_a_bird_house315.jpg', 'bird_going_inside_a_bird_house350.jpg', 'bird_going_inside_a_bird_house385.jpg', 'bird_going_inside_a_bird_house420.jpg', 'bird_going_inside_a_bird_house455.jpg', 'bird_going_inside_a_bird_house490.jpg', 'bird_going_inside_a_bird_house525.jpg', 'bird_going_inside_a_bird_house560.jpg', 'bird_going_inside_a_bird_house595.jpg', 'bird_going_inside_a_bird_house630.jpg', 'bird_going_inside_a_bird_house665.jpg', 'bird_going_inside_a_bird_house700.jpg', 'bird_going_inside_a_bird_house735.jpg', 'bird_going_inside_a_bird_house770.jpg', 'bird_going_inside_a_bird_house805.jpg', 'bird_going_inside_a_bird_house840.jpg', 'bird_going_inside_a_bird_house875.jpg', 'bird_going_inside_a_bird_house910.jpg', 'bird_going_inside_a_bird_house945.jpg', 'bird_going_inside_a_bird_house980.jpg', 'bird_going_inside_a_bird_house1015.jpg', 'bird_going_inside_a_bird_house1050.jpg', 'bird_going_inside_a_bird_house1085.jpg', 'bird_going_inside_a_bird_house1120.jpg']\n"
     ]
    }
   ],
   "source": [
    "print(frame_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "df129aa6-163d-4a6c-8a8b-d1b883b59847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: ../video_frame/4/bird_going_inside_a_bird_house1015.jpg to s3://sagemaker-us-west-2-691188012938/videokeyframe/bird_going_inside_a_bird_house1015.jpg\n",
      "upload: ../video_frame/4/bird_going_inside_a_bird_house175.jpg to s3://sagemaker-us-west-2-691188012938/videokeyframe/bird_going_inside_a_bird_house175.jpg\n",
      "upload: ../video_frame/4/bird_going_inside_a_bird_house105.jpg to s3://sagemaker-us-west-2-691188012938/videokeyframe/bird_going_inside_a_bird_house105.jpg\n",
      "upload: ../video_frame/4/bird_going_inside_a_bird_house1120.jpg to s3://sagemaker-us-west-2-691188012938/videokeyframe/bird_going_inside_a_bird_house1120.jpg\n",
      "upload: ../video_frame/4/bird_going_inside_a_bird_house1085.jpg to s3://sagemaker-us-west-2-691188012938/videokeyframe/bird_going_inside_a_bird_house1085.jpg\n",
      "upload: ../video_frame/4/bird_going_inside_a_bird_house280.jpg to s3://sagemaker-us-west-2-691188012938/videokeyframe/bird_going_inside_a_bird_house280.jpg\n",
      "upload: ../video_frame/4/bird_going_inside_a_bird_house1050.jpg to s3://sagemaker-us-west-2-691188012938/videokeyframe/bird_going_inside_a_bird_house1050.jpg\n",
      "upload: ../video_frame/4/bird_going_inside_a_bird_house210.jpg to s3://sagemaker-us-west-2-691188012938/videokeyframe/bird_going_inside_a_bird_house210.jpg\n",
      "upload: ../video_frame/4/bird_going_inside_a_bird_house140.jpg to s3://sagemaker-us-west-2-691188012938/videokeyframe/bird_going_inside_a_bird_house140.jpg\n",
      "upload: ../video_frame/4/bird_going_inside_a_bird_house35.jpg to s3://sagemaker-us-west-2-691188012938/videokeyframe/bird_going_inside_a_bird_house35.jpg\n",
      "upload: ../video_frame/4/bird_going_inside_a_bird_house245.jpg to s3://sagemaker-us-west-2-691188012938/videokeyframe/bird_going_inside_a_bird_house245.jpg\n",
      "upload: ../video_frame/4/bird_going_inside_a_bird_house315.jpg to s3://sagemaker-us-west-2-691188012938/videokeyframe/bird_going_inside_a_bird_house315.jpg\n",
      "upload: ../video_frame/4/bird_going_inside_a_bird_house350.jpg to s3://sagemaker-us-west-2-691188012938/videokeyframe/bird_going_inside_a_bird_house350.jpg\n",
      "upload: ../video_frame/4/bird_going_inside_a_bird_house385.jpg to s3://sagemaker-us-west-2-691188012938/videokeyframe/bird_going_inside_a_bird_house385.jpg\n",
      "upload: ../video_frame/4/bird_going_inside_a_bird_house525.jpg to s3://sagemaker-us-west-2-691188012938/videokeyframe/bird_going_inside_a_bird_house525.jpg\n",
      "upload: ../video_frame/4/bird_going_inside_a_bird_house560.jpg to s3://sagemaker-us-west-2-691188012938/videokeyframe/bird_going_inside_a_bird_house560.jpg\n",
      "upload: ../video_frame/4/bird_going_inside_a_bird_house420.jpg to s3://sagemaker-us-west-2-691188012938/videokeyframe/bird_going_inside_a_bird_house420.jpg\n",
      "upload: ../video_frame/4/bird_going_inside_a_bird_house490.jpg to s3://sagemaker-us-west-2-691188012938/videokeyframe/bird_going_inside_a_bird_house490.jpg\n",
      "upload: ../video_frame/4/bird_going_inside_a_bird_house455.jpg to s3://sagemaker-us-west-2-691188012938/videokeyframe/bird_going_inside_a_bird_house455.jpg\n",
      "upload: ../video_frame/4/bird_going_inside_a_bird_house595.jpg to s3://sagemaker-us-west-2-691188012938/videokeyframe/bird_going_inside_a_bird_house595.jpg\n",
      "upload: ../video_frame/4/bird_going_inside_a_bird_house630.jpg to s3://sagemaker-us-west-2-691188012938/videokeyframe/bird_going_inside_a_bird_house630.jpg\n",
      "upload: ../video_frame/4/bird_going_inside_a_bird_house735.jpg to s3://sagemaker-us-west-2-691188012938/videokeyframe/bird_going_inside_a_bird_house735.jpg\n",
      "upload: ../video_frame/4/bird_going_inside_a_bird_house70.jpg to s3://sagemaker-us-west-2-691188012938/videokeyframe/bird_going_inside_a_bird_house70.jpg\n",
      "upload: ../video_frame/4/bird_going_inside_a_bird_house770.jpg to s3://sagemaker-us-west-2-691188012938/videokeyframe/bird_going_inside_a_bird_house770.jpg\n",
      "upload: ../video_frame/4/bird_going_inside_a_bird_house945.jpg to s3://sagemaker-us-west-2-691188012938/videokeyframe/bird_going_inside_a_bird_house945.jpg\n",
      "upload: ../video_frame/4/bird_going_inside_a_bird_house700.jpg to s3://sagemaker-us-west-2-691188012938/videokeyframe/bird_going_inside_a_bird_house700.jpg\n",
      "upload: ../video_frame/4/bird_going_inside_a_bird_house805.jpg to s3://sagemaker-us-west-2-691188012938/videokeyframe/bird_going_inside_a_bird_house805.jpg\n",
      "upload: ../video_frame/4/bird_going_inside_a_bird_house910.jpg to s3://sagemaker-us-west-2-691188012938/videokeyframe/bird_going_inside_a_bird_house910.jpg\n",
      "upload: ../video_frame/4/bird_going_inside_a_bird_house875.jpg to s3://sagemaker-us-west-2-691188012938/videokeyframe/bird_going_inside_a_bird_house875.jpg\n",
      "upload: ../video_frame/4/bird_going_inside_a_bird_house840.jpg to s3://sagemaker-us-west-2-691188012938/videokeyframe/bird_going_inside_a_bird_house840.jpg\n",
      "upload: ../video_frame/4/bird_going_inside_a_bird_house980.jpg to s3://sagemaker-us-west-2-691188012938/videokeyframe/bird_going_inside_a_bird_house980.jpg\n",
      "upload: ../video_frame/4/bird_going_inside_a_bird_house665.jpg to s3://sagemaker-us-west-2-691188012938/videokeyframe/bird_going_inside_a_bird_house665.jpg\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp --recursive {frame_path} s3://{bucket}/{s3_frame_prefix}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632284fe-39e3-473f-a58e-086dc0be2b4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9adb64-8f47-4969-b9d4-335cdd389bca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2af32882-3587-4832-9948-36d36d87b050",
   "metadata": {},
   "source": [
    "## 2.2 利用VLM 产生内容描述"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3987ea64-7038-4020-8144-8895fd072b8f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import base64\n",
    "import json\n",
    "import boto3\n",
    "\n",
    "smr_client = boto3.client(\"sagemaker-runtime\")\n",
    "endpoint_name = model.endpoint_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "dae73ace-0aea-4379-9083-471b168d62bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def encode_image(img_file):\n",
    "    with open(img_file, \"rb\") as image_file:\n",
    "        img_str = base64.b64encode(image_file.read())\n",
    "        base64_string = img_str.decode(\"latin1\")\n",
    "    return base64_string\n",
    "\n",
    "def run_inference(endpoint_name, inputs):\n",
    "    response = smr_client.invoke_endpoint(\n",
    "        EndpointName=endpoint_name, Body=json.dumps(inputs)\n",
    "    )\n",
    "    return response[\"Body\"].read().decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "2a8f152b-dba5-4996-8813-120708655f77",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "content_result_list=[]\n",
    "length_output_params = {\n",
    "    \"max_new_tokens\": 70,\n",
    "    \"min_new_tokens\": 30,\n",
    "    \"early_stopping\": True\n",
    "}\n",
    "\n",
    "# Parameters that control the generation strategy used\n",
    "gen_strategy_params = {\n",
    "    \"do_sample\": False,\n",
    "    \"num_beams\": 2,\n",
    "    \"num_beam_groups\": 1,\n",
    "    \"use_cache\": True\n",
    "}\n",
    "\n",
    "gen_strategy_params.update(length_output_params)\n",
    "\n",
    "for item in frame_list:\n",
    "    image_path=frame_path+item\n",
    "    raw_image = Image.open(image_path).convert('RGB')\n",
    "    \n",
    "    base64_string = encode_image(image_path)\n",
    "    inputs = {\"prompt\": \"please describe this image.\", \"image\": base64_string,\"parameters\": gen_strategy_params}\n",
    "    result=run_inference(endpoint_name, inputs)\n",
    "    content_result_list.append(result)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "#test_image = \"../video_frame/2/33632_315.jpg.jpeg\"\n",
    "#raw_image = Image.open(test_image).convert('RGB')\n",
    "#display(raw_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a7736c52-1095-4d89-9c71-04ec71ca30d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a bird is sitting in a birdhouse in a garden with a tree in the foreground and bushes in the back ground', 'a blue bird is sitting in a birdhouse in a garden surrounded by trees and shrubs a birdhouse in a garden', 'a birdhouse with a small bird inside of it and a tree in the back yard with a bird in the birdhouse and a tree in the back yard', 'a wooden birdhouse with a hole in the side and a bird in the nest on the roof of the birdhouse - birdhouses', 'a wooden birdhouse with a hole in the side and a bird in the nest on the roof of the birdhouse - birdhouses', 'a birdhouse with a small bird inside of it and a tree behind the birdhouse - a birdhouse with a small bird inside', 'a birdhouse with a bird in the hole and a tree in the back yard with a bird in the hole and a tree in the back yard with a bird in the hole', 'a wooden birdhouse with a hole in the side and a bird in the nest on the roof of the birdhouse - birdhouses', \"a wooden birdhouse with a hole in the side and a bird on it's nest in it's nesting box in the garden\", 'a birdhouse with a small bird inside of it and a tree behind the birdhouse - a birdhouse with a small bird inside', 'a birdhouse with a hole in the side and a bird in the nesting box on the side of the birdhouse - birdhouses', \"a birdhouse with a hole in the side and a bird on it's nest in it's nesting box in the garden\", 'a birdhouse with a bird in it and a tree in the back yard with a bird in the birdhouse and a tree in the background', 'a birdhouse with a hole in the side and a hole in the top of the birdhouse, a wooden birdhouse with a hole in the side', 'a birdhouse with a small bird inside of it and a tree behind the birdhouse - tit birdhouse - tit birdhouse', 'a birdhouse with a small bird inside of it and a tree behind the birdhouse - tit birdhouse - birdhouses', 'a birdhouse with a small bird inside of it and a tree in the background - birdhouses - birdhouses - birdhouses', 'a birdhouse with a hole in the side and a wooden frame on the side of the birdhouse, with a wooden frame on the side', 'a birdhouse with a blue bird in the window of the birdhouse - a birdhouse with a blue bird in the window of the birdhouse', 'a birdhouse with a hole in the side and a small bird inside of the birdhouse - birdhouses - birdhouses', 'a birdhouse with a small bird in it on a wooden fence in a garden with a tree in the foreground and bushes', 'a birdhouse with a blue bird in the window of the birdhouse - a birdhouse for a blue thrush - a blue thrush birdhouse', 'a birdhouse with a hole in the side and a wooden frame on the side of the birdhouse, with a wooden frame on the side', 'a birdhouse with a blue bird inside of it and a green leaf on the side of the birdhouse - tit birdhouse', 'a birdhouse with a hole in the side and a hole in the top of the birdhouse - birdhouses - birdhouses', 'a wooden birdhouse with a hole in the side and a small hole in the top of the birdhouse - birdhouses - birdhouses', 'a birdhouse with a hole in the side and a blue bird in the hole in the side of the birdhouse - birdhouses', 'a wooden birdhouse with a hole in the side and a small hole in the top of the birdhouse - birdhouses uk', 'a wooden birdhouse with a clock on the side of the house in a garden with a tree in the foreground and bushes behind', 'a birdhouse with a small bird inside of it and a tree in the back yard with a tree in the front yard with a tree in the back yard with a tree in the front yard', 'a wooden birdhouse with a clock on the side of the house and a bird on the top of the birdhouse - birdhouses', 'a birdhouse with a hole in the side and a small hole in the top of the birdhouse - birdhouses uk']\n"
     ]
    }
   ],
   "source": [
    "print(content_result_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33012996-b4f8-492c-9f4d-cad5079c79e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f289d1c-eba2-488a-8346-e70a8babe7dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "40d0b880-31fa-403c-9cf1-ab6a07ae1e0c",
   "metadata": {},
   "source": [
    "## 3.使用Bedrock Claude进行不同任务"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "18ddcacd-dd45-43d4-95b8-748d117cdbba",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (0.0.330)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langchain) (2.0.23)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langchain) (3.8.6)\n",
      "Requirement already satisfied: anyio<4.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langchain) (3.7.1)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langchain) (4.0.3)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langchain) (0.6.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langchain) (1.33)\n",
      "Requirement already satisfied: langsmith<0.1.0,>=0.0.52 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langchain) (0.0.57)\n",
      "Requirement already satisfied: numpy<2,>=1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langchain) (1.26.1)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langchain) (2.4.2)\n",
      "Requirement already satisfied: requests<3,>=2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langchain) (8.2.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (3.3.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: idna>=2.8 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from anyio<4.0->langchain) (3.4)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from anyio<4.0->langchain) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from anyio<4.0->langchain) (1.1.3)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.20.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.10.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (2.10.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (4.8.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests<3,>=2->langchain) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2023.7.22)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.1)\n",
      "Requirement already satisfied: packaging>=17.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.7,>=0.5.7->langchain) (21.3)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from packaging>=17.0->marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.7,>=0.5.7->langchain) (3.1.1)\n",
      "Requirement already satisfied: anthropic in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (0.5.0)\n",
      "Requirement already satisfied: anyio<4,>=3.5.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from anthropic) (3.7.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from anthropic) (1.8.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from anthropic) (0.25.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from anthropic) (2.4.2)\n",
      "Requirement already satisfied: tokenizers>=0.13.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from anthropic) (0.14.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from anthropic) (4.8.0)\n",
      "Requirement already satisfied: idna>=2.8 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from anyio<4,>=3.5.0->anthropic) (3.4)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from anyio<4,>=3.5.0->anthropic) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from anyio<4,>=3.5.0->anthropic) (1.1.3)\n",
      "Requirement already satisfied: certifi in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from httpx<1,>=0.23.0->anthropic) (2023.7.22)\n",
      "Requirement already satisfied: httpcore in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from httpx<1,>=0.23.0->anthropic) (1.0.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->anthropic) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.10.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->anthropic) (2.10.1)\n",
      "Requirement already satisfied: huggingface_hub<0.18,>=0.16.4 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from tokenizers>=0.13.0->anthropic) (0.17.3)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface_hub<0.18,>=0.16.4->tokenizers>=0.13.0->anthropic) (3.12.4)\n",
      "Requirement already satisfied: fsspec in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface_hub<0.18,>=0.16.4->tokenizers>=0.13.0->anthropic) (2023.10.0)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface_hub<0.18,>=0.16.4->tokenizers>=0.13.0->anthropic) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface_hub<0.18,>=0.16.4->tokenizers>=0.13.0->anthropic) (4.66.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface_hub<0.18,>=0.16.4->tokenizers>=0.13.0->anthropic) (6.0.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface_hub<0.18,>=0.16.4->tokenizers>=0.13.0->anthropic) (21.3)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from httpcore->httpx<1,>=0.23.0->anthropic) (0.14.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from packaging>=20.9->huggingface_hub<0.18,>=0.16.4->tokenizers>=0.13.0->anthropic) (3.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->huggingface_hub<0.18,>=0.16.4->tokenizers>=0.13.0->anthropic) (3.3.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->huggingface_hub<0.18,>=0.16.4->tokenizers>=0.13.0->anthropic) (1.26.18)\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain\n",
    "!pip install anthropic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ae56632c-070e-4e0d-88dc-14928720566e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create new client\n",
      "  Using region: None\n",
      "boto3 Bedrock client successfully created!\n",
      "bedrock-runtime(https://bedrock-runtime.us-west-2.amazonaws.com)\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms.bedrock import Bedrock\n",
    "from langchain import LLMChain, PromptTemplate\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import boto3\n",
    "import botocore\n",
    "\n",
    "from utils import bedrock\n",
    "\n",
    "boto3_bedrock = bedrock.get_bedrock_client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "dbb71e73-fd6d-4dff-a672-65b0780793c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms.bedrock import Bedrock\n",
    "\n",
    "inference_modifier = {'max_tokens_to_sample':4096, \n",
    "                      \"temperature\":0.5,\n",
    "                      \"top_k\":250,\n",
    "                      \"top_p\":1,\n",
    "                      \"stop_sequences\": [\"\\n\\nHuman\"]\n",
    "                     }\n",
    "\n",
    "textgen_llm = Bedrock(model_id = \"anthropic.claude-v2\",\n",
    "                    client = boto3_bedrock, \n",
    "                    model_kwargs = inference_modifier \n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65162192-934e-40ba-925c-ef51703d923a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d1cb793b-2d79-4306-9211-3ec2907b6bd0",
   "metadata": {},
   "source": [
    "### 3.1 视频摘要（Video Summary）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "803c5bf9-508d-4db0-802d-a4c6c15c4e81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our prompt has 1099 tokens\n"
     ]
    }
   ],
   "source": [
    "with open('./utils/video_summary.txt', 'r', encoding=\"utf-8\") as task:\n",
    "    lines = task.readlines()\n",
    "    multi_var_prompt = PromptTemplate(\n",
    "    input_variables=[\"input\"], \n",
    "    template=\"\"\"\n",
    "\n",
    "        Human: {}\n",
    "\n",
    "        Assistant: Here is a simple video summary: \"\"\".format(lines)\n",
    "        )\n",
    "    prompt = multi_var_prompt.format(input=str(content_result_list))\n",
    "    num_tokens = textgen_llm.get_num_tokens(prompt)\n",
    "    print(f\"Our prompt has {num_tokens} tokens\")\n",
    "    \n",
    "    response = textgen_llm(prompt)\n",
    "    content = response[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "3adeed7b-78bc-4048-bbef-ce03de8342ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "This video shows a birdhouse in a garden with trees and bushes in the background. A small bird is sitting inside the birdhouse or on its roof. The birdhouse is made of wood and has holes on the sides and top for the bird to enter and exit. The video focuses on capturing the birdhouse from different angles with the bird inside its nest.\n"
     ]
    }
   ],
   "source": [
    "print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc4f3ba-6bf2-4ca3-93a8-3189b531b7f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d331216c-58ed-4a18-88bf-3611f945e819",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "557f4134-5a2e-4083-b228-55976cbed2e2",
   "metadata": {},
   "source": [
    "### 3.2 社交圈文案生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "a80eccd7-e3c1-49a1-a2a5-b5293c7c3475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our prompt has 1355 tokens\n"
     ]
    }
   ],
   "source": [
    "with open('./utils/social_media_post.txt', 'r', encoding=\"utf-8\") as task:\n",
    "    lines = task.readlines()\n",
    "    multi_var_prompt = PromptTemplate(\n",
    "    input_variables=[\"input\"], \n",
    "    template=\"\"\"\n",
    "\n",
    "        Human: {}\n",
    "\n",
    "        Assistant: ok \"\"\".format(lines)\n",
    "        )\n",
    "    prompt = multi_var_prompt.format(input=str(content_result_list))\n",
    "    num_tokens = textgen_llm.get_num_tokens(prompt)\n",
    "    print(f\"Our prompt has {num_tokens} tokens\")\n",
    "    \n",
    "    response = textgen_llm(prompt)\n",
    "    content = response[response.index('\\n')+1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "3e9a66e0-c7c1-4e2a-93df-852d53f2e37d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "😊 This video shows some precious moments with my little feathered friend! Over the past year, I've had the joy of watching a sweet bird make its home in the wooden birdhouse in my backyard. \n",
      "\n",
      "Through changing seasons, my new neighbor stuck around, peeking its head out of the round hole in its cozy abode. I loved seeing its bright blue feathers and hearing its cheerful chirps on sunny mornings. \n",
      "\n",
      "Some of my favorite memories were watching it dart in and out of its home, perched up high on the birdhouse roof or nestled inside. No matter how much time passed, it always recognized me when I came outside. \n",
      "\n",
      "I feel so lucky to have made a new friend! This little bird brought me comfort and made me smile during difficult days. I hope it continues to stay in the neighborhood so we can enjoy more special moments together. 🐦\n"
     ]
    }
   ],
   "source": [
    "print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f305a4-f00f-4d3a-a2f0-fe2ddf214387",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f99130-f7f9-4ceb-9f0d-9b4a29af4977",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6ca80ed4-6f15-4c5d-a4a0-c333a8eb1b00",
   "metadata": {},
   "source": [
    "### 3.3 基于图像的问答"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "b5b0f1cd-f5c4-4d08-bb74-eeaf2d680f94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our prompt has 1068 tokens\n"
     ]
    }
   ],
   "source": [
    "with open('./utils/VQA.txt', 'r', encoding=\"utf-8\") as task:\n",
    "    lines = task.readlines()\n",
    "    multi_var_prompt = PromptTemplate(\n",
    "    input_variables=[\"input\",\"question\"], \n",
    "    template=\"\"\"\n",
    "\n",
    "        Human: {}\n",
    "\n",
    "        Assistant: \"\"\".format(lines)\n",
    "        )\n",
    "    prompt = multi_var_prompt.format(input=str(content_result_list),question=\"What kind of bird appeared today? \")\n",
    "    num_tokens = textgen_llm.get_num_tokens(prompt)\n",
    "    print(f\"Our prompt has {num_tokens} tokens\")\n",
    "    \n",
    "    response = textgen_llm(prompt)\n",
    "    content = response[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "3b57a487-35aa-438d-8979-3528de4bc3c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blue bird\n"
     ]
    }
   ],
   "source": [
    "print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab5e373-25c7-4d01-9a54-66f8ae47e20b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22616f1c-a919-4f77-af58-de3a0bbffe06",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sm_client.delete_model(ModelName=model_name)\n",
    "# sm_client.delete_endpoint(EndpointName=endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d7d3ff-5ae5-4aa1-9f29-bf71abe4dcc7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
